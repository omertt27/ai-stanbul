# ğŸš€ Data Collection Activation Plan - Start Model Fine-tuning

**Date:** December 9, 2024  
**Status:** ğŸŸ¢ **READY TO LAUNCH**  
**Goal:** Collect 10,000+ high-quality chat interactions for Llama 3.1 fine-tuning

---

## âœ… Infrastructure Status

### Already Implemented âœ…
1. **Backend Data Collection** (`backend/services/data_collection.py`)
   - âœ… Chat interaction logging
   - âœ… User feedback tracking
   - âœ… Privacy-compliant anonymization
   - âœ… Statistics tracking
   - âœ… Export to JSONL format

2. **API Endpoints** (`backend/api/feedback.py`)
   - âœ… `/api/feedback/submit` - Submit user feedback
   - âœ… `/api/feedback/stats` - View collection stats
   - âœ… `/api/feedback/export` - Export training dataset

3. **Chat API Integration** (`backend/api/chat.py`)
   - âœ… Automatic logging of all chat interactions
   - âœ… Metadata tracking (language, intent, response time)
   - âœ… Session and user ID tracking

### Missing Components ğŸ”§
1. **Frontend Feedback UI** - User thumbs up/down buttons
2. **Admin Dashboard** - Monitor collection progress
3. **Data Directory Setup** - Create training_data folder
4. **Monitoring Script** - Track collection stats

---

## ğŸ“‹ Implementation Checklist

### Phase 1: Activate Data Collection (TODAY)

#### Step 1.1: Create Data Directory âœ…
```bash
cd /Users/omer/Desktop/ai-stanbul/backend
mkdir -p training_data
chmod 755 training_data
```

#### Step 1.2: Add Feedback UI to Chatbot âš¡
Add thumbs up/down buttons to each message:
- Location: `frontend/src/Chatbot.jsx`
- UI: Subtle feedback buttons below each AI response
- API: Call `/api/feedback/submit` on click
- UX: Show "Thanks for feedback!" confirmation

#### Step 1.3: Create Monitoring Dashboard âš¡
Simple HTML dashboard to view stats:
- Location: `backend/admin/data_collection_dashboard.html`
- Shows: Total interactions, feedback rate, languages, intents
- Updates: Real-time via `/api/feedback/stats`

#### Step 1.4: Enable Logging in Production âœ…
Verify logging is active:
- Check `backend/api/chat.py` line 539
- Ensure `log_chat_interaction()` is called
- Test with a few queries

---

### Phase 2: Monitor & Optimize (WEEK 1)

#### Daily Tasks:
1. **Check Collection Stats**
   ```bash
   curl http://localhost:8000/api/feedback/stats
   ```
   
2. **Review Data Quality**
   ```bash
   tail -f backend/training_data/chat_logs.jsonl
   ```

3. **Monitor Feedback Rate**
   - Target: >10% of users leave feedback
   - Goal: >70% positive feedback

#### Optimization Targets:
- **Interactions per day:** 100-200 (goal: 10,000 total)
- **Feedback rate:** >10%
- **Positive rate:** >70%
- **Language distribution:** 60% EN, 30% TR, 10% other
- **Intent coverage:** All major intents represented

---

### Phase 3: Data Preparation (AFTER 5,000+ INTERACTIONS)

#### Step 3.1: Export Training Dataset
```bash
# Export filtered, high-quality data
curl -X POST http://localhost:8000/api/feedback/export \
  -H "Content-Type: application/json" \
  -d '{"filter_positive_only": true, "min_response_length": 50, "max_response_length": 400}'
```

#### Step 3.2: Quality Review
- Manual review of 100 random samples
- Check for PII (remove if found)
- Verify response quality
- Balance language distribution

#### Step 3.3: Data Augmentation
Create additional training examples:
- Synthetic data generation (GPT-4)
- Paraphrased variations
- Istanbul-specific FAQs
- Restaurant/attraction data

#### Step 3.4: Final Dataset Split
```bash
python scripts/split_dataset.py \
  --input training_dataset.jsonl \
  --train 0.9 \
  --val 0.05 \
  --test 0.05
```

---

## ğŸ“Š Success Metrics

### Minimum Viable Dataset (MVP)
- âœ… **5,000 total interactions**
- âœ… **500+ with positive feedback**
- âœ… **Mix of languages:** EN, TR, AR, FR, DE, RU
- âœ… **Intent coverage:** >80% of intent types
- âœ… **Quality score:** >70% positive feedback

### Ideal Dataset (BEST)
- âœ… **10,000+ total interactions**
- âœ… **1,500+ with positive feedback**
- âœ… **Balanced languages:** 60% EN, 30% TR, 10% other
- âœ… **Full intent coverage:** 100% of intent types
- âœ… **Quality score:** >80% positive feedback

---

## ğŸ¯ Next Actions (DO NOW)

### Immediate (Next 30 Minutes)
1. âœ… Create `backend/training_data` directory
2. âš¡ Add feedback buttons to `Chatbot.jsx`
3. âš¡ Create monitoring dashboard
4. âœ… Test data collection with sample queries

### This Week
1. Monitor collection daily
2. Promote chat usage (social media, ads)
3. Add feedback incentives ("Help improve AI!")
4. Fix any issues in data quality

### This Month
1. Reach 5,000 interactions milestone
2. Export and review dataset
3. Add synthetic data (2,000-3,000 examples)
4. Prepare for fine-tuning

---

## ğŸ”§ Quick Start Commands

### Start Backend (with logging enabled)
```bash
cd /Users/omer/Desktop/ai-stanbul/backend
python main.py
```

### Check Stats
```bash
curl http://localhost:8000/api/feedback/stats | jq
```

### View Recent Logs
```bash
tail -20 backend/training_data/chat_logs.jsonl | jq
```

### Export Dataset
```bash
curl -X POST http://localhost:8000/api/feedback/export | jq
```

---

## ğŸ“ Notes

### Privacy & Compliance
- âœ… User IDs are anonymized (SHA-256 hash)
- âœ… No PII stored (names, emails, phone numbers)
- âœ… Location data generalized to city-level
- âœ… Can delete specific user data on request

### Data Quality
- Focus on high-quality, helpful responses
- Filter out errors and hallucinations
- Prefer responses with positive feedback
- Include diverse query types

### Timeline
- **Week 1-4:** Active collection (5,000+ interactions)
- **Week 5:** Data preparation & augmentation
- **Week 6:** Fine-tuning & evaluation
- **Week 7:** Deployment & A/B testing

---

## ğŸš€ Launch Checklist

Before activating data collection, verify:
- [ ] Backend is running
- [ ] Training data directory exists
- [ ] Feedback API endpoints work
- [ ] Frontend feedback UI added
- [ ] Monitoring dashboard created
- [ ] Initial stats show data is being logged

**All systems ready? Let's collect some data! ğŸ‰**
