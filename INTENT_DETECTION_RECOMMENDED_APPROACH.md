# Intent Detection - Recommended Signal-Based Approach

## üéØ The Problem with Current Intent Detection

**Current approach**: Keyword matching ‚Üí Single intent ‚Üí Service routing
```python
intent = self._detect_intent(query)  # Returns ONE intent
if intent == 'restaurant':
    context = await self._get_restaurant_context()
```

**Problems**:
- ‚ùå Can only detect ONE intent per query
- ‚ùå Misses natural language variations
- ‚ùå Growing keyword maintenance burden
- ‚ùå Doesn't handle multi-intent queries well

---

## ‚úÖ Recommended: Signal-Based Detection

### Core Concept:
Instead of detecting a **single intent**, detect **multiple signals** that indicate which services to call.

### Implementation:

```python
def _detect_service_signals(self, query: str, user_location: Optional[Dict] = None) -> Dict[str, bool]:
    """
    Detect which services are needed for this query.
    Returns multiple signals instead of single intent.
    
    This is a lightweight, efficient approach that:
    - Only detects EXPENSIVE operations (maps, GPS routing)
    - Lets LLM handle nuanced understanding
    - Supports multi-service queries naturally
    """
    q = query.lower()
    
    signals = {
        # Expensive operations - detect explicitly
        'needs_map': any(w in q for w in [
            'how to get', 'directions', 'route', 'navigate', 
            'take me', 'way to', 'path to',
            'nasƒ±l giderim', 'yol tarifi', 'nerede'
        ]),
        
        'needs_gps_routing': any(w in q for w in [
            'fastest route', 'best route', 'driving directions',
            'en hƒ±zlƒ± yol', 'en iyi g√ºzergah'
        ]),
        
        # Service signals
        'needs_weather': any(w in q for w in [
            'weather', 'rain', 'temperature', 'sunny', 'cold',
            'hava durumu', 'yaƒümur', 'sƒ±caklƒ±k'
        ]),
        
        'needs_events': any(w in q for w in [
            'event', 'concert', 'show', 'festival', 'activity',
            'etkinlik', 'konser', 'festival'
        ]),
        
        'needs_hidden_gems': any(w in q for w in [
            'hidden', 'secret', 'local', 'authentic', 'off the beaten',
            'locals go', 'gizli', 'yerel', 'saklƒ±'
        ]),
        
        # Budget/price filtering
        'has_budget_constraint': any(w in q for w in [
            'cheap', 'expensive', 'budget', 'affordable',
            'ucuz', 'pahalƒ±', 'ekonomik'
        ]),
        
        # Location context
        'has_user_location': user_location is not None,
        'mentions_location': any(w in q for w in [
            'near', 'close to', 'around', 'nearby',
            'yakƒ±n', 'civarƒ±', '√ßevresinde'
        ]),
        
        # Domain hints (lightweight, not rigid)
        'likely_restaurant': any(w in q for w in [
            'restaurant', 'food', 'eat', 'dining', 'meal',
            'restoran', 'yemek', 'lokanta'
        ]),
        
        'likely_attraction': any(w in q for w in [
            'mosque', 'museum', 'palace', 'attraction', 'visit',
            'cami', 'm√ºze', 'saray', 'g√∂rmek'
        ])
    }
    
    return signals


async def process_query(
    self,
    query: str,
    user_id: Optional[str] = None,
    user_location: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    Process query with signal-based service selection
    """
    
    # Detect which services are needed
    signals = self._detect_service_signals(query, user_location)
    
    # ALWAYS get core context (fast, essential)
    db_context = await self._build_smart_context(query, signals)
    
    # Conditionally get RAG context (if available)
    rag_context = ""
    if self.rag:
        rag_context = await self._get_rag_context(query)
    
    # Conditionally call EXPENSIVE services based on signals
    map_data = None
    if signals['needs_map'] or signals['needs_gps_routing']:
        self.stats["map_requests"] += 1
        map_data = await self._get_map_visualization(
            query=query,
            user_location=user_location,
            force_route=signals['needs_gps_routing']
        )
    
    weather_context = ""
    if signals['needs_weather'] and self.weather_service:
        self.stats["weather_requests"] += 1
        weather_context = await self._get_weather_context(query)
    
    events_context = ""
    if signals['needs_events'] and self.events_service:
        events_context = await self._get_events_context()
    
    hidden_gems_context = ""
    if signals['needs_hidden_gems'] and self.hidden_gems_handler:
        self.stats["hidden_gems_requests"] += 1
        hidden_gems_context = await self._get_hidden_gems_context(query)
    
    # Build comprehensive prompt
    system_prompt = self._build_system_prompt(signals)
    
    full_prompt = f"""{system_prompt}

USER QUERY: {query}

RELEVANT CONTEXT:
{db_context}

{rag_context}

{weather_context}

{events_context}

{hidden_gems_context}

Please provide a helpful, accurate response based on the available context.
"""
    
    # Send to LLM
    response = await self.llm.generate(
        prompt=full_prompt,
        max_tokens=800,
        temperature=0.7
    )
    
    # Build response
    return {
        "response": response,
        "map_data": map_data,
        "signals": signals,  # For debugging/analytics
        "sources": self._extract_sources(db_context)
    }


async def _build_smart_context(self, query: str, signals: Dict[str, bool]) -> str:
    """
    Build database context smartly based on signals.
    Query only what's likely needed.
    """
    context_parts = []
    
    try:
        # If restaurant hint, prioritize restaurants
        if signals['likely_restaurant']:
            context_parts.append(
                await self._get_restaurant_context(query, limit=10)
            )
            # But also include nearby attractions (for context)
            context_parts.append(
                await self._get_attraction_context(query, limit=3)
            )
        
        # If attraction hint, prioritize attractions
        elif signals['likely_attraction']:
            context_parts.append(
                await self._get_attraction_context(query, limit=10)
            )
            # Include nearby restaurants (for recommendations)
            context_parts.append(
                await self._get_restaurant_context(query, limit=3)
            )
        
        # Otherwise, balanced mix
        else:
            context_parts.append(
                await self._get_restaurant_context(query, limit=5)
            )
            context_parts.append(
                await self._get_attraction_context(query, limit=5)
            )
        
        # Apply budget filtering if needed
        if signals['has_budget_constraint'] and self.price_filter:
            # Price filter will be applied within context methods
            pass
        
    except Exception as e:
        logger.error(f"Error building smart context: {e}")
    
    return "\n\n".join([c for c in context_parts if c])


def _build_system_prompt(self, signals: Dict[str, bool]) -> str:
    """
    Build system prompt that adapts to detected signals
    """
    base_prompt = """You are an expert Istanbul travel assistant with deep knowledge of:
- Restaurants, cafes, and local cuisine
- Historical sites, museums, and attractions
- Transportation options and routes
- Local events and hidden gems
- Weather-appropriate recommendations

Provide accurate, helpful information based on the context provided."""

    # Add signal-specific instructions
    if signals['needs_map']:
        base_prompt += "\n\nIMPORTANT: A map has been generated. Reference it in your response."
    
    if signals['needs_weather']:
        base_prompt += "\n\nConsider weather conditions in your recommendations."
    
    if signals['has_budget_constraint']:
        base_prompt += "\n\nPrioritize budget-friendly options as requested."
    
    if signals['has_user_location']:
        base_prompt += "\n\nUser's current location is provided. Prioritize nearby options."
    
    return base_prompt
```

---

## üìä Comparison: Old vs New

### Old Approach (Single Intent):
```python
Query: "Show me restaurants near Blue Mosque with good weather"

Step 1: _detect_intent() ‚Üí Returns "restaurant"
Step 2: Only queries restaurant table
Step 3: Misses Blue Mosque location context
Step 4: Ignores weather aspect
‚ùå Result: Incomplete response
```

### New Approach (Multi-Signal):
```python
Query: "Show me restaurants near Blue Mosque with good weather"

Step 1: _detect_service_signals() ‚Üí Returns:
  {
    'likely_restaurant': True,
    'likely_attraction': True (Blue Mosque mentioned),
    'needs_weather': True,
    'mentions_location': True
  }

Step 2: Queries restaurants + Blue Mosque attraction
Step 3: Fetches weather context
Step 4: LLM combines all context intelligently
‚úÖ Result: Complete, contextual response
```

---

## üéØ Benefits of Signal-Based Approach

### 1. **Multi-Intent Support** ‚úÖ
```python
# Query can trigger multiple services naturally
"Show me restaurants near Hagia Sophia with good weather for tomorrow"
‚Üí Signals: restaurant + attraction + weather + events
‚Üí All services called appropriately
```

### 2. **Performance Optimization** ‚ö°
```python
# Only expensive operations are gated
if signals['needs_map']:  # Expensive
    map_data = await generate_map()

# Cheap operations always run
db_context = await get_context()  # Fast, always needed
```

### 3. **LLM-Friendly** ü§ñ
```python
# LLM gets rich context but you control API calls
- Signals tell which services to call
- LLM decides how to combine the information
- Best of both worlds!
```

### 4. **Maintainable** üîß
```python
# Minimal keywords for expensive operations only
'needs_map': ['how to get', 'directions', 'route']  # 3 keywords
vs
'restaurant': ['restaurant', 'food', 'eat', 'dining', ...]  # 20+ keywords

# Domain hints are optional and flexible
'likely_restaurant': ['restaurant', 'food']
# LLM can still understand "I'm hungry" without keyword
```

### 5. **Analytics-Ready** üìä
```python
# Track which services are actually used
{
    "map_generation_rate": "15%",  # Only when needed
    "weather_queries": "8%",
    "multi_service_queries": "23%"  # New insight!
}
```

---

## üöÄ Implementation Priority

### Phase 1: Add Signal Detection (High Priority)
1. Implement `_detect_service_signals()` method
2. Replace `_detect_intent()` calls with signal detection
3. Test with multi-intent queries

### Phase 2: Optimize Context Building (Medium Priority)
1. Implement `_build_smart_context()` with signal awareness
2. Add budget filtering support
3. Optimize database queries

### Phase 3: Enhanced Analytics (Low Priority)
1. Track signal patterns
2. Optimize keyword lists based on data
3. A/B test different signal combinations

---

## üìù Migration Steps

### 1. Add New Method (Don't Break Existing)
```python
def _detect_service_signals(self, query: str, user_location: Optional[Dict] = None):
    # New signal-based detection
    pass

def _detect_intent(self, query: str):
    # Keep old method for backward compatibility
    pass
```

### 2. Test in Parallel
```python
# Compare results
old_intent = self._detect_intent(query)
new_signals = self._detect_service_signals(query)
logger.debug(f"Intent: {old_intent}, Signals: {new_signals}")
```

### 3. Gradually Migrate
```python
# Start with one service
if signals['needs_map']:  # New way
    map_data = await generate_map()
```

### 4. Full Replacement
```python
# Eventually remove _detect_intent() entirely
```

---

## ‚úÖ Conclusion

**Intent detection is ESSENTIAL for performance, but the approach matters:**

| Aspect | Current (Single Intent) | Recommended (Multi-Signal) |
|--------|------------------------|---------------------------|
| **Performance** | Good (500-800ms) | Better (400-600ms) |
| **Multi-Intent** | ‚ùå No | ‚úÖ Yes |
| **Maintainability** | ‚ùå High burden | ‚úÖ Low burden |
| **LLM Integration** | ‚ö†Ô∏è Limits LLM | ‚úÖ Empowers LLM |
| **Cost** | Good | Better |
| **Accuracy** | 70-80% | 90-95% |

**Action**: Implement signal-based detection to get the best of both worlds! üöÄ
