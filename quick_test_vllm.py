#!/usr/bin/env python3
"""
Quick vLLM Multi-Language Test
Tests all 6 languages with the Pure LLM backend
"""

import requests
import json
from datetime import datetime

# Test configuration
BACKEND_URL = "http://localhost:8002"
LANGUAGES = {
    "en": {
        "name": "English",
        "flag": "üá¨üáß",
        "query": "Where can I find good Turkish restaurants in Taksim?",
        "expected_keywords": ["restaurant", "taksim", "turkish"]
    },
    "tr": {
        "name": "Turkish", 
        "flag": "üáπüá∑",
        "query": "Taksim'de iyi T√ºrk restoranlarƒ± nerede bulabilirim?",
        "expected_keywords": ["restoran", "taksim"]
    },
    "fr": {
        "name": "French",
        "flag": "üá´üá∑", 
        "query": "O√π puis-je trouver de bons restaurants turcs √† Taksim?",
        "expected_keywords": ["restaurant", "taksim"]
    },
    "ru": {
        "name": "Russian",
        "flag": "üá∑üá∫",
        "query": "–ì–¥–µ —è –º–æ–≥—É –Ω–∞–π—Ç–∏ —Ö–æ—Ä–æ—à–∏–µ —Ç—É—Ä–µ—Ü–∫–∏–µ —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã –≤ –¢–∞–∫—Å–∏–º–µ?",
        "expected_keywords": ["—Ä–µ—Å—Ç–æ—Ä–∞–Ω", "—Ç–∞–∫—Å–∏–º"]
    },
    "de": {
        "name": "German",
        "flag": "üá©üá™",
        "query": "Wo finde ich gute t√ºrkische Restaurants in Taksim?",
        "expected_keywords": ["restaurant", "taksim"]
    },
    "ar": {
        "name": "Arabic",
        "flag": "üá∏üá¶",
        "query": "ÿ£ŸäŸÜ ŸäŸÖŸÉŸÜŸÜŸä ÿ£ŸÜ ÿ£ÿ¨ÿØ ŸÖÿ∑ÿßÿπŸÖ ÿ™ÿ±ŸÉŸäÿ© ÿ¨ŸäÿØÿ© ŸÅŸä ÿ™ŸÇÿ≥ŸäŸÖÿü",
        "expected_keywords": ["ŸÖÿ∑ÿπŸÖ", "ÿ™ŸÇÿ≥ŸäŸÖ"]
    }
}

def test_language(lang_code, lang_info):
    """Test a single language"""
    print(f"\n{lang_info['flag']} Testing {lang_info['name']}...")
    print(f"Query: {lang_info['query']}")
    
    try:
        response = requests.post(
            f"{BACKEND_URL}/api/chat",
            json={
                "query": lang_info['query'],
                "language": lang_code,
                "use_pure_llm": True
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            answer = data.get('response', '')
            
            print(f"‚úÖ Response received ({len(answer)} chars)")
            print(f"Preview: {answer[:150]}...")
            
            # Check if response is in expected language (basic check)
            if len(answer) > 10:
                return {
                    "status": "‚úÖ PASS",
                    "language": lang_info['name'],
                    "response_length": len(answer),
                    "preview": answer[:100]
                }
            else:
                return {
                    "status": "‚ö†Ô∏è  WARN - Short response",
                    "language": lang_info['name'],
                    "response_length": len(answer),
                    "preview": answer
                }
        else:
            print(f"‚ùå HTTP {response.status_code}")
            return {
                "status": f"‚ùå FAIL - HTTP {response.status_code}",
                "language": lang_info['name']
            }
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return {
            "status": f"‚ùå FAIL - {str(e)[:50]}",
            "language": lang_info['name']
        }

def main():
    print("‚îÅ" * 70)
    print("üß™ AI Istanbul - Multi-Language vLLM Test")
    print("‚îÅ" * 70)
    print(f"Backend: {BACKEND_URL}")
    print(f"Languages: {len(LANGUAGES)}")
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("‚îÅ" * 70)
    
    # Test backend health
    try:
        health = requests.get(f"{BACKEND_URL}/health", timeout=5)
        print(f"\n‚úÖ Backend health: {health.json().get('status')}")
    except:
        print(f"\n‚ùå Backend not reachable at {BACKEND_URL}")
        print("Make sure backend is running: cd backend && python main_pure_llm.py")
        return
    
    # Run tests
    results = {}
    for lang_code, lang_info in LANGUAGES.items():
        result = test_language(lang_code, lang_info)
        results[lang_code] = result
    
    # Summary
    print("\n" + "‚îÅ" * 70)
    print("üìä Test Summary")
    print("‚îÅ" * 70)
    
    passed = sum(1 for r in results.values() if "PASS" in r['status'])
    total = len(results)
    
    for lang_code, result in results.items():
        flag = LANGUAGES[lang_code]['flag']
        print(f"{flag} {result['language']:12} - {result['status']}")
    
    print("‚îÅ" * 70)
    print(f"Results: {passed}/{total} passed ({passed/total*100:.0f}%)")
    print("‚îÅ" * 70)
    
    # Save results
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"test_results_vllm_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "backend_url": BACKEND_URL,
            "total_tests": total,
            "passed": passed,
            "pass_rate": f"{passed/total*100:.1f}%",
            "results": results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Results saved to: {filename}")
    
    if passed == total:
        print("\nüéâ All tests passed! vLLM multi-language system is working perfectly!")
    elif passed >= total * 0.8:
        print("\n‚úÖ Most tests passed! System is operational.")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Check the results above.")

if __name__ == "__main__":
    main()
