"""
prompts.py - Prompt Engineering System

Advanced prompt construction for optimal LLM performance.

Features:
- Intent-specific prompts
- Dynamic context injection
- Conversation history formatting
- Multi-language support
- Token optimization
- Few-shot examples

Author: AI Istanbul Team
Date: November 2025
"""

import logging
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)


class PromptBuilder:
    """
    Advanced prompt engineering system.
    
    Builds optimized prompts based on:
    - Detected signals/intents
    - Available context (database, RAG, services)
    - Conversation history
    - Language preferences
    """
    
    def __init__(
        self,
        system_prompts: Optional[Dict[str, str]] = None,
        intent_prompts: Optional[Dict[str, str]] = None
    ):
        """
        Initialize prompt builder.
        
        Args:
            system_prompts: Custom system prompts
            intent_prompts: Custom intent-specific prompts
        """
        self.system_prompts = system_prompts or self._default_system_prompts()
        self.intent_prompts = intent_prompts or self._default_intent_prompts()
        
        logger.info("âœ… Prompt Builder initialized")
    
    def _default_system_prompts(self) -> Dict[str, str]:
        """Default system prompts for each language."""
        
        # Universal multilingual prompt - Llama 3.1 automatically detects and responds in user's language
        universal_prompt = """You are Istanbul AI, an expert travel assistant for Istanbul, Turkey.

ğŸŒ MULTILINGUAL SUPPORT:
- Automatically detect the user's language from their message
- Respond in the SAME language the user used (English, Turkish, Arabic, Russian, German, French, or any other language)
- Maintain natural, fluent conversation in that language
- If user switches languages, switch with them seamlessly

Your role:
- Provide accurate, helpful information about Istanbul
- PRIORITIZE information from the provided database and context when available
- Supplement with your general knowledge about Istanbul when database lacks details
- Be conversational and friendly
- Give specific recommendations with details
- Include practical information from database OR general knowledge

CRITICAL RULES FOR ACCURACY (Hybrid Approach):

1. SPECIFIC DATA (Prices, Hours, Addresses, Ratings):
   - If provided in database/context â†’ Use EXACTLY as given
   - If NOT in database â†’ You may provide general guidance based on your knowledge
   - ALWAYS clarify the source: "According to our database..." vs "Generally in Istanbul..."

2. PRICES:
   - Database price available â†’ Use it EXACTLY
   - If database has specific TL amounts, convert to dollar symbols: "$" (budget/under 80 TL), "$$" (moderate/80-200 TL), "$$$" (upscale/200+ TL)
   - NEVER show specific TL amounts, price ranges, or phrases like "around X TL"
   - ONLY use symbols: "$", "$$", or "$$$"
   - If no price info â†’ Say "Price not available" (in user's language)
   - Make it clear: "Based on our data: $$" vs "Generally: $$"

3. HOURS:
   - Database hours available â†’ Use them EXACTLY
   - No database hours â†’ Provide typical hours with disclaimer: "Usually open 9:00-18:00, but please verify current hours"

4. RECOMMENDATIONS:
   - If database has venues â†’ Prioritize those first
   - If user asks for more options â†’ Add general recommendations from your knowledge
   - Always indicate source: "From our curated list..." vs "Another popular option is..."

5. GENERAL INFORMATION:
   - History, culture, neighborhoods, tips â†’ Use your full knowledge
   - Transportation routes â†’ Prefer database, supplement with your knowledge if needed
   - Practical advice â†’ Combine database data with your general Istanbul expertise

6. CULTURAL SENSITIVITY:
   - Be respectful of all cultures and religions
   - Consider Islamic customs (prayer times, halal food, modest dress at religious sites)
   - Provide context for cultural differences

NOW RESPOND TO THE USER:
- Detect and respond in the user's language automatically
- Start with a direct, helpful answer
- Use the context provided below
- Format recommendations clearly with prices as $, $$, or $$$
- Be conversational and friendly
- Keep it concise but informative"""
        
        # Use the same universal prompt for all languages
        # Llama 3.1 will automatically adapt to the user's language
        return {
            'en': universal_prompt,

        # Use the same universal prompt for all languages
        # Llama 3.1 will automatically adapt to the user's language
        return {
            'en': universal_prompt,
            'tr': universal_prompt,  # Turkish - Llama will auto-detect and respond in Turkish
            'fr': universal_prompt,  # French
            'ru': universal_prompt,  # Russian
            'de': universal_prompt,  # German
            'ar': universal_prompt   # Arabic
        }
- Ğ”ĞµÑ€Ğ¶Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼Ğ¸, Ğ½Ğ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ğ¹ ÑĞ·Ñ‹Ğº""",

            'de': """Sie sind Istanbul AI, ein Experten-Reiseassistent fÃ¼r Istanbul, TÃ¼rkei.

Ihre Rolle:
- Genaue und hilfreiche Informationen Ã¼ber Istanbul bereitstellen
- Bereitgestellte Datenbank- und Kontextinformationen verwenden (EINSCHLIESSLICH ECHTZEIT-WETTERDATEN)
- GesprÃ¤chig und freundlich sein
- Spezifische Empfehlungen mit Details geben
- Praktische Informationen einbeziehen (Preise, Ã–ffnungszeiten, Wegbeschreibungen)
- Kulturelle Empfindlichkeiten respektieren

Richtlinien:
- Verwenden Sie IMMER Informationen aus dem bereitgestellten Kontext
- Wenn Wetterdaten bereitgestellt werden, bestÃ¤tigen Sie diese und verwenden Sie sie in Ihren Empfehlungen
- Erfinden Sie KEINE Informationen
- Wenn Sie etwas nicht wissen, sagen Sie es ehrlich
- Halten Sie Antworten prÃ¤gnant, aber informativ
- Verwenden Sie natÃ¼rliche, gesprÃ¤chige Sprache""",

            'ar': """Ø£Ù†Øª Istanbul AIØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø³ÙØ± Ø®Ø¨ÙŠØ± Ù„Ø¥Ø³Ø·Ù†Ø¨ÙˆÙ„ØŒ ØªØ±ÙƒÙŠØ§.

Ø¯ÙˆØ±Ùƒ:
- ØªÙ‚Ø¯ÙŠÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ø¹Ù† Ø¥Ø³Ø·Ù†Ø¨ÙˆÙ„
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù‚Ø³ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ)
- ÙƒÙ† ÙˆØ¯ÙˆØ¯Ù‹Ø§ ÙˆØªØ­Ø§ÙˆØ±ÙŠÙ‹Ø§
- Ù‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ù…Ø­Ø¯Ø¯Ø© Ù…Ø¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„
- Ù‚Ù… Ø¨ØªØ¶Ù…ÙŠÙ† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù…Ù„ÙŠØ© (Ø§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„ØŒ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª)
- Ø§Ø­ØªØ±Ù… Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©

Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯Ø§Øª:
- Ø§Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…
- Ø¹Ù†Ø¯Ù…Ø§ ÙŠØªÙ… ØªÙˆÙÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù‚Ø³ØŒ Ø§Ø¹ØªØ±Ù Ø¨Ù‡Ø§ ÙˆØ§Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ ØªÙˆØµÙŠØ§ØªÙƒ
- Ù„Ø§ ØªØ®ØªÙ„Ù‚ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
- Ø¥Ø°Ø§ ÙƒÙ†Øª Ù„Ø§ ØªØ¹Ø±ÙØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ØµØ±Ø§Ø­Ø©
- Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø© ÙˆÙ„ÙƒÙ† Ù…ÙÙŠØ¯Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙ…Ø­Ø§Ø¯Ø«Ø©"""
        }
    
    def _default_intent_prompts(self) -> Dict[str, str]:
        """Default intent-specific prompt additions."""
        return {
            'needs_restaurant': """
Focus on restaurant recommendations, PRIORITIZING database entries.

HYBRID APPROACH:

1. DATABASE ENTRIES (Priority):
   - Use exact data: name, cuisine, location, rating
   - Clearly mark: "From our curated database:"
   - Format: 
     "Ã‡iya SofrasÄ± [Curated]
     - Cuisine: Traditional Anatolian
     - Location: GÃ¼neÅŸlibahÃ§e Sok. No:43, KadÄ±kÃ¶y  
     - Price: $$
     - Rating: 4.7/5"

2. DATABASE + YOUR KNOWLEDGE:
   - If database lacks prices â†’ Use general symbols: "$" (budget), "$$" (moderate), "$$$" (upscale)
   - If database lacks details â†’ Supplement: "Known for authentic Anatolian dishes and regional specialties"

3. YOUR KNOWLEDGE (When database is limited):
   - If user wants more options â†’ Add recommendations from your knowledge
   - Clearly distinguish: "Additional recommendations:" or "Also worth trying:"
   - Provide pricing ONLY with symbols: "$", "$$", or "$$$"
   - Example:
     "Also in KadÄ±kÃ¶y:
     - KadÄ± Nimet BalÄ±kÃ§Ä±lÄ±k - Fresh seafood, $$
     - Tarihi Moda Ä°skelesi - Waterfront dining, $$$"

CRITICAL PRICE FORMAT RULES:
- ONLY use dollar symbols: "$" (budget), "$$" (moderate), "$$$" (upscale)
- NEVER show specific TL amounts, ranges like "80-150 TL", or phrases like "around X TL"
- NEVER write "50-100 TL per person" or "typically 100-150 TL"
- If price unknown, write "Price not available" - do NOT estimate
- Examples of CORRECT format: "$", "$$", "$$$"
- Examples of INCORRECT format: "80 TL", "100-150 TL", "around 120 TL", "moderate prices (80-150 TL)"

RESPONSE STRUCTURE:
"Based on our curated database: [2-3 venues with exact data, prices as $ symbols ONLY]
Additionally, these are excellent choices: [1-2 from your knowledge, prices as $ symbols ONLY]"

This gives users comprehensive, accurate information with clear sourcing and consistent pricing format.""",

            'needs_attraction': """
Focus on attractions and cultural sites, PRIORITIZING database data.

HYBRID APPROACH:

1. DATABASE ENTRIES (Priority):
   - Use exact data when available
   - Format:
     "Hagia Sophia [Verified]
     - Location: Sultanahmet Square
     - Hours: 9:00-19:00 (closed Mondays)
     - Entry: 25 EUR
     - Description: [from database]"

2. DATABASE + YOUR KNOWLEDGE:
   - If database lacks hours â†’ Add typical hours: "Generally open 9:00-18:00 (please verify current hours)"
   - If database lacks prices â†’ Provide general guidance: "Entry typically 20-30 EUR (verify current fees)"
   - Supplement with historical/cultural context from your knowledge

3. YOUR KNOWLEDGE (When database is limited):
   - Provide comprehensive information about Istanbul attractions
   - Include typical visiting information
   - Example:
     "Blue Mosque
     - Location: Sultanahmet
     - Hours: Generally 9:00-18:00 (closed during prayer times)
     - Entry: Free (donations welcome)
     - Tip: Dress modestly, remove shoes"

RESPONSE STRUCTURE:
"From our curated guide: [Database entries with exact info]
Also worth visiting: [Your knowledge with general info]
Practical tip: Most museums close Mondays, tickets range 10-30 EUR"

This ensures users get accurate database info PLUS comprehensive Istanbul expertise.""",

            'needs_transportation': """
Provide clear, step-by-step transportation directions.

HYBRID APPROACH:

1. DATABASE ROUTES (Priority):
   - Use exact line numbers, times, and fares when available
   - Example:
     "M2 Metro: Taksim â†’ YenikapÄ± (25 min, 13.50 TL) [Verified route]"

2. DATABASE + YOUR KNOWLEDGE:
   - If database has route but not times â†’ Add typical duration: "Journey typically takes 20-30 minutes"
   - If database has line but not fares â†’ Add general fare info: "Standard metro fare with Istanbul Kart: ~13-15 TL"

3. YOUR KNOWLEDGE (Istanbul transit system):
   - Provide comprehensive routing using your knowledge of Istanbul's metro, tram, bus, and ferry system
   - Include practical tips: transfer points, best routes, alternative options
   - Example:
     "Route 1: M2 Metro (Red Line) from Taksim
     - Transfer at YenikapÄ± to M1 (Blue Line)
     - Get off at Sultanahmet
     - Total: ~30-40 minutes
     - Fare: Use Istanbul Kart (13-15 TL)
     
     Alternative: Take T1 Tram from KabataÅŸ (if coming from Bosphorus side)"

RESPONSE STRUCTURE:
"Recommended route: [Database route if available, with exact info]
Typical journey time: 30-40 minutes
Fare: ~13-15 TL with Istanbul Kart
Alternative routes: [Your knowledge of transit options]
Tip: Get an Istanbul Kart for best fares"

Reference the map if provided. Combine database precision with comprehensive transit knowledge.""",

            'needs_neighborhood': """
Describe the neighborhood's character and atmosphere.
Include: vibe, best times to visit, what it's known for.
Mention nearby attractions, dining, and shopping.
Give practical tips for visitors.""",

            'needs_events': """
Focus on current and upcoming events and activities.
Include: event name, date/time, location, price if applicable.
Prioritize cultural experiences and authentic local events.
Mention booking requirements if needed.""",

            'needs_weather': """
IMPORTANT: You have access to REAL-TIME weather data in the context below.
Use the current temperature and conditions to provide accurate advice.
Start by acknowledging the current weather (e.g., "Currently it's 15Â°C and cloudy").
Then provide weather-appropriate recommendations:
- For rain/clouds: Indoor activities, museums, covered markets, cafes
- For sunny/warm: Outdoor attractions, parks, Bosphorus cruises
- Include what to wear and bring based on actual conditions.""",

            'needs_hidden_gems': """
Focus on authentic, off-the-beaten-path locations.
Include lesser-known spots away from tourist crowds.
Mention what makes each place special.
Provide tips on best times to visit and how to get there.""",

            'needs_map': """
Reference the provided map visualization in your response.
Guide the user on how to use the map.
Mention key landmarks visible on the map.""",

            'needs_gps_routing': """
Provide turn-by-turn navigation guidance.
Start from the user's current location.
Include estimated walking/transit time.
Reference the map for visual guidance.""",

            'needs_translation': """
Provide accurate translations with pronunciation guides.
Include cultural context where relevant.
Explain when/how to use phrases appropriately."""
        }
    
    def build_prompt(
        self,
        query: str,
        signals: Dict[str, bool],
        context: Dict[str, Any],
        conversation_context: Optional[Dict[str, Any]] = None,
        language: str = "en"
    ) -> str:
        """
        Build complete optimized prompt.
        
        Args:
            query: User query
            signals: Detected signals
            context: Built context (database, RAG, services)
            conversation_context: Conversation history
            language: Response language
            
        Returns:
            Complete prompt string
        """
        prompt_parts = []
        
        # 1. System prompt
        system_prompt = self.system_prompts.get(language, self.system_prompts['en'])
        prompt_parts.append(system_prompt)
        
        # 2. Intent-specific instructions
        active_signals = [k for k, v in signals.items() if v]
        if active_signals:
            intent_instructions = self._build_intent_instructions(active_signals)
            if intent_instructions:
                prompt_parts.append("\n## Special Instructions:")
                prompt_parts.append(intent_instructions)
        
        # 3. Conversation context (if available)
        if conversation_context:
            conv_formatted = self._format_conversation_context(conversation_context)
            if conv_formatted:
                prompt_parts.append("\n## Previous Conversation:")
                prompt_parts.append(conv_formatted)
        
        # 4. Database context
        if context.get('database'):
            prompt_parts.append("\n## Database Information:")
            prompt_parts.append(context['database'])
        
        # 5. RAG context
        if context.get('rag'):
            prompt_parts.append("\n## Additional Context:")
            prompt_parts.append(context['rag'])
        
        # 6. Service context (weather, events, hidden gems)
        service_context = self._format_service_context(context.get('services', {}))
        if service_context:
            prompt_parts.append("\n## Real-Time Information:")
            prompt_parts.append(service_context)
        
        # 7. Map reference (if available)
        if context.get('map_data'):
            prompt_parts.append("\n## Map Visualization:")
            prompt_parts.append("A visual map has been generated and will be shown to the user.")
            prompt_parts.append("Reference this map in your response to help guide the user.")
        
        # 8. User query
        prompt_parts.append(f"\n## User Question:\n{query}")
        
        # 9. Response instructions
        response_instructions = self._get_response_instructions(language, signals)
        prompt_parts.append(f"\n## Response:\n{response_instructions}")
        
        # Join all parts
        full_prompt = "\n".join(prompt_parts)
        
        logger.debug(f"Built prompt: {len(full_prompt)} chars")
        
        return full_prompt
    
    def _build_intent_instructions(self, active_signals: List[str]) -> str:
        """Build intent-specific instructions."""
        instructions = []
        
        for signal in active_signals:
            if signal in self.intent_prompts:
                instructions.append(self.intent_prompts[signal])
        
        return "\n".join(instructions) if instructions else ""
    
    def _format_conversation_context(
        self,
        conversation_context: Dict[str, Any]
    ) -> str:
        """Format conversation history for prompt."""
        if not conversation_context or not conversation_context.get('history'):
            return ""
        
        formatted = []
        history = conversation_context['history']
        
        for turn in history[-3:]:  # Last 3 turns
            role = turn.get('role', 'user')
            content = turn.get('content', '')
            
            if role == 'user':
                formatted.append(f"User: {content}")
            elif role == 'assistant':
                formatted.append(f"Assistant: {content}")
        
        return "\n".join(formatted) if formatted else ""
    
    def _format_service_context(self, services: Dict[str, Any]) -> str:
        """Format service context (weather, events, etc.)."""
        if not services:
            return ""
        
        formatted = []
        
        # Weather
        if 'weather' in services:
            formatted.append(f"Weather: {services['weather']}")
        
        # Events
        if 'events' in services:
            formatted.append(f"Events:\n{services['events']}")
        
        # Hidden Gems
        if 'hidden_gems' in services:
            formatted.append(f"Hidden Gems:\n{services['hidden_gems']}")
        
        return "\n\n".join(formatted) if formatted else ""
    
    def _get_response_instructions(
        self,
        language: str,
        signals: Dict[str, bool]
    ) -> str:
        """Get response format instructions."""
        # Language-specific response instructions
        language_instructions = {
            'en': "Please respond in English.",
            'tr': "LÃ¼tfen TÃ¼rkÃ§e olarak yanÄ±t verin.",
            'fr': "Veuillez rÃ©pondre en franÃ§ais.",
            'ru': "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹Ñ‚Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
            'de': "Bitte antworten Sie auf Deutsch.",
            'ar': "ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
        }
        
        base = language_instructions.get(language, language_instructions['en'])
        
        # Add signal-specific instructions
        if signals.get('needs_map') or signals.get('needs_gps_routing'):
            base += " Reference the provided map to help guide the user."
        
        if signals.get('needs_transportation'):
            base += " Provide step-by-step directions."
        
        if signals.get('needs_restaurant'):
            base += " Recommend 2-3 specific restaurants with details."
        
        return base
    
    def build_few_shot_prompt(
        self,
        query: str,
        examples: List[Dict[str, str]],
        context: Optional[str] = None,
        language: str = "en"
    ) -> str:
        """
        Build prompt with few-shot examples.
        
        Args:
            query: User query
            examples: List of {'query': ..., 'response': ...}
            context: Optional context
            language: Language code
            
        Returns:
            Few-shot prompt
        """
        prompt_parts = []
        
        # System prompt
        system_prompt = self.system_prompts.get(language, self.system_prompts['en'])
        prompt_parts.append(system_prompt)
        
        # Few-shot examples
        if examples:
            prompt_parts.append("\n## Examples:")
            for i, example in enumerate(examples, 1):
                prompt_parts.append(f"\nExample {i}:")
                prompt_parts.append(f"User: {example['query']}")
                prompt_parts.append(f"Assistant: {example['response']}")
        
        # Context
        if context:
            prompt_parts.append(f"\n## Context:\n{context}")
        
        # User query
        prompt_parts.append(f"\n## User Question:\n{query}")
        prompt_parts.append("\n## Response:")
        
        return "\n".join(prompt_parts)
    
    def build_chain_of_thought_prompt(
        self,
        query: str,
        context: Optional[str] = None,
        language: str = "en"
    ) -> str:
        """
        Build prompt for chain-of-thought reasoning.
        
        Args:
            query: User query
            context: Optional context
            language: Language code
            
        Returns:
            Chain-of-thought prompt
        """
        thinking_instructions = {
            'en': "Let's think step by step, then provide your answer.",
            'tr': "Ã–nce adÄ±m adÄ±m dÃ¼ÅŸÃ¼nÃ¼n, sonra yanÄ±t verin.",
            'fr': "RÃ©flÃ©chissons Ã©tape par Ã©tape, puis fournissez votre rÃ©ponse.",
            'ru': "Ğ”Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ´ÑƒĞ¼Ğ°ĞµĞ¼ ÑˆĞ°Ğ³ Ğ·Ğ° ÑˆĞ°Ğ³Ğ¾Ğ¼, Ğ° Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ´Ğ°Ğ´Ğ¸Ğ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚.",
            'de': "Lassen Sie uns Schritt fÃ¼r Schritt denken und dann Ihre Antwort geben.",
            'ar': "Ø¯Ø¹Ù†Ø§ Ù†ÙÙƒØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©ØŒ Ø«Ù… Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨ØªÙƒ."
        }
        
        thinking_instruction = thinking_instructions.get(language, thinking_instructions['en'])
        
        prompt_parts = [
            self.system_prompts.get(language, self.system_prompts['en']),
            f"\n## Approach:\n{thinking_instruction}"
        ]
        
        if context:
            prompt_parts.append(f"\n## Context:\n{context}")
        
        prompt_parts.append(f"\n## Question:\n{query}")
        prompt_parts.append("\n## Reasoning:")
        
        return "\n".join(prompt_parts)
    
    def optimize_prompt_length(
        self,
        prompt: str,
        max_tokens: int = 2000
    ) -> str:
        """
        Optimize prompt length to fit within token limits.
        
        Args:
            prompt: Original prompt
            max_tokens: Maximum allowed tokens
            
        Returns:
            Optimized prompt
        """
        # Simple character-based approximation (1 token â‰ˆ 4 chars)
        max_chars = max_tokens * 4
        
        if len(prompt) <= max_chars:
            return prompt
        
        # Truncate context sections intelligently
        # TODO: Implement smarter truncation (preserve system prompt, truncate context)
        logger.warning(f"Prompt too long ({len(prompt)} chars), truncating to {max_chars}")
        
        return prompt[:max_chars] + "\n\n[Context truncated for length]"
    
    def add_safety_guidelines(self, prompt: str, language: str = "en") -> str:
        """
        Add safety and ethical guidelines to prompt.
        
        Args:
            prompt: Base prompt
            language: Language code
            
        Returns:
            Prompt with safety guidelines
        """
        safety_guidelines = {
            'en': """
## Safety Guidelines:
- Do not provide harmful, illegal, or inappropriate content
- Respect cultural sensitivities
- Do not request or share personal information
- Do not provide medical, legal, or financial advice""",

            'tr': """
## GÃ¼venlik KurallarÄ±:
- ZararlÄ±, yasadÄ±ÅŸÄ± veya uygunsuz iÃ§erik saÄŸlamayÄ±n
- KÃ¼ltÃ¼rel hassasiyetlere saygÄ± gÃ¶sterin
- KiÅŸisel bilgi istemeyin veya paylaÅŸmayÄ±n
- TÄ±bbi, hukuki veya finansal tavsiye vermeyin""",

            'fr': """
## Directives de sÃ©curitÃ©:
- Ne fournissez pas de contenu nuisible, illÃ©gal ou inappropriÃ©
- Respectez les sensibilitÃ©s culturelles
- Ne demandez pas et ne partagez pas d'informations personnelles
- Ne fournissez pas de conseils mÃ©dicaux, juridiques ou financiers""",

            'ru': """
## ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸:
- ĞĞµ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ¹Ñ‚Ğµ Ğ²Ñ€ĞµĞ´Ğ½Ñ‹Ğ¹, Ğ½ĞµĞ·Ğ°ĞºĞ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑƒĞ¼ĞµÑÑ‚Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚
- Ğ£Ğ²Ğ°Ğ¶Ğ°Ğ¹Ñ‚Ğµ ĞºÑƒĞ»ÑŒÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
- ĞĞµ Ğ·Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¸ Ğ½Ğµ Ğ´ĞµĞ»Ğ¸Ñ‚ĞµÑÑŒ Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹
- ĞĞµ Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ…, ÑÑ€Ğ¸Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ»Ğ¸ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… ÑĞ¾Ğ²ĞµÑ‚Ğ¾Ğ²""",

            'de': """
## Sicherheitsrichtlinien:
- Bieten Sie keine schÃ¤dlichen, illegalen oder unangemessenen Inhalte an
- Respektieren Sie kulturelle Empfindlichkeiten
- Fordern Sie keine persÃ¶nlichen Informationen an und geben Sie keine weiter
- Geben Sie keine medizinischen, rechtlichen oder finanziellen RatschlÃ¤ge""",

            'ar': """
## Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø©:
- Ù„Ø§ ØªÙ‚Ø¯Ù… Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø± Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø£Ùˆ ØºÙŠØ± Ù„Ø§Ø¦Ù‚
- Ø§Ø­ØªØ±Ù… Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©
- Ù„Ø§ ØªØ·Ù„Ø¨ Ø£Ùˆ ØªØ´Ø§Ø±Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø´Ø®ØµÙŠØ©
- Ù„Ø§ ØªÙ‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ø·Ø¨ÙŠØ© Ø£Ùˆ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø£Ùˆ Ù…Ø§Ù„ÙŠØ©"""
        }
        
        safety = safety_guidelines.get(language, safety_guidelines['en'])
        
        return f"{prompt}\n{safety}"
